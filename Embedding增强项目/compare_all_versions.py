#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
é¢„å¤„ç†è„šæœ¬ç‰ˆæœ¬å¯¹æ¯”åˆ†æå·¥å…·
å¯¹æ¯”V1ã€V2ã€V3ä¸‰ä¸ªç‰ˆæœ¬çš„å¤„ç†æ•ˆæœ

åŠŸèƒ½ï¼š
1. åŠ è½½ä¸‰ä¸ªç‰ˆæœ¬çš„ç»Ÿè®¡æ•°æ®
2. å¯¹æ¯”å…³é”®æŒ‡æ ‡
3. åˆ†ææ”¹è¿›æ•ˆæœ
4. ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š

ä½œè€…: RAGé¢„å¤„ç†ä¸“å®¶
ç‰ˆæœ¬: 1.0
"""

import json
import argparse
from typing import Dict, Any, List
from dataclasses import dataclass

@dataclass
class VersionStats:
    """ç‰ˆæœ¬ç»Ÿè®¡ä¿¡æ¯"""
    version: str
    total_chunks: int
    avg_chunk_size: float
    avg_quality_score: float
    boundary_quality_score: float
    size_distribution: Dict[str, int]
    forced_splits: int = 0
    boundary_candidates: int = 0

class VersionComparator:
    """ç‰ˆæœ¬å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¯¹æ¯”å™¨"""
        self.versions = {}
    
    def load_v1_data(self, quality_file: str) -> VersionStats:
        """
        åŠ è½½V1ç‰ˆæœ¬æ•°æ®ï¼ˆä»quality_report.jsonï¼‰
        
        Args:
            quality_file (str): V1è´¨é‡æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
            
        Returns:
            VersionStats: V1ç‰ˆæœ¬ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            with open(quality_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # ä»V1æ•°æ®ä¸­æå–ä¿¡æ¯
            chunks_info = data.get('chunks_analysis', {})
            total_chunks = chunks_info.get('total_chunks', 0)
            
            # è®¡ç®—å¹³å‡åˆ†å—å¤§å°
            chunk_sizes = chunks_info.get('chunk_sizes', [])
            avg_size = sum(chunk_sizes) / len(chunk_sizes) if chunk_sizes else 0
            
            # è´¨é‡åˆ†æ•°
            quality_scores = chunks_info.get('quality_scores', [])
            avg_quality = sum(quality_scores) / len(quality_scores) if quality_scores else 0
            
            # è¾¹ç•Œè´¨é‡ï¼ˆé«˜è´¨é‡åˆ†å—æ¯”ä¾‹ï¼‰
            high_quality = sum(1 for score in quality_scores if score > 0.7)
            boundary_quality = high_quality / len(quality_scores) if quality_scores else 0
            
            # å¤§å°åˆ†å¸ƒ
            size_dist = {
                'small': sum(1 for size in chunk_sizes if size < 400),
                'medium': sum(1 for size in chunk_sizes if 400 <= size <= 800),
                'large': sum(1 for size in chunk_sizes if 800 < size <= 1500),
                'extra_large': sum(1 for size in chunk_sizes if size > 1500)
            }
            
            return VersionStats(
                version="V1",
                total_chunks=total_chunks,
                avg_chunk_size=avg_size,
                avg_quality_score=avg_quality,
                boundary_quality_score=boundary_quality,
                size_distribution=size_dist
            )
            
        except Exception as e:
            print(f"âŒ åŠ è½½V1æ•°æ®å¤±è´¥: {e}")
            raise
    
    def load_v2_v3_data(self, stats_file: str, version: str) -> VersionStats:
        """
        åŠ è½½V2/V3ç‰ˆæœ¬æ•°æ®ï¼ˆä»processing_stats.jsonï¼‰
        
        Args:
            stats_file (str): ç»Ÿè®¡æ–‡ä»¶è·¯å¾„
            version (str): ç‰ˆæœ¬å·ï¼ˆV2æˆ–V3ï¼‰
            
        Returns:
            VersionStats: ç‰ˆæœ¬ç»Ÿè®¡ä¿¡æ¯
        """
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–ç»Ÿè®¡ä¿¡æ¯
            stats = data.get('statistics', {})
            processing_info = data.get('processing_info', {})
            
            return VersionStats(
                version=version,
                total_chunks=stats.get('total_chunks', 0),
                avg_chunk_size=stats.get('average_chunk_size', 0),
                avg_quality_score=stats.get('average_quality_score', 0),
                boundary_quality_score=stats.get('boundary_quality_score', 0),
                size_distribution=stats.get('size_distribution', {}),
                forced_splits=processing_info.get('forced_splits', 0),
                boundary_candidates=processing_info.get('boundary_candidates_found', 0)
            )
            
        except Exception as e:
            print(f"âŒ åŠ è½½{version}æ•°æ®å¤±è´¥: {e}")
            raise
    
    def calculate_improvements(self, baseline: VersionStats, current: VersionStats) -> Dict[str, float]:
        """
        è®¡ç®—æ”¹è¿›ç™¾åˆ†æ¯”
        
        Args:
            baseline (VersionStats): åŸºçº¿ç‰ˆæœ¬
            current (VersionStats): å½“å‰ç‰ˆæœ¬
            
        Returns:
            Dict[str, float]: æ”¹è¿›ç™¾åˆ†æ¯”å­—å…¸
        """
        improvements = {}
        
        # åˆ†å—æ•°é‡å˜åŒ–
        if baseline.total_chunks > 0:
            improvements['chunks_change'] = ((current.total_chunks - baseline.total_chunks) / baseline.total_chunks) * 100
        
        # å¹³å‡åˆ†å—å¤§å°å˜åŒ–
        if baseline.avg_chunk_size > 0:
            improvements['size_change'] = ((current.avg_chunk_size - baseline.avg_chunk_size) / baseline.avg_chunk_size) * 100
        
        # è´¨é‡åˆ†æ•°æ”¹è¿›
        if baseline.avg_quality_score > 0:
            improvements['quality_improvement'] = ((current.avg_quality_score - baseline.avg_quality_score) / baseline.avg_quality_score) * 100
        
        # è¾¹ç•Œè´¨é‡æ”¹è¿›
        if baseline.boundary_quality_score > 0:
            improvements['boundary_improvement'] = ((current.boundary_quality_score - baseline.boundary_quality_score) / baseline.boundary_quality_score) * 100
        
        return improvements
    
    def analyze_size_distribution(self, versions: List[VersionStats]) -> Dict[str, Any]:
        """
        åˆ†æå¤§å°åˆ†å¸ƒå˜åŒ–
        
        Args:
            versions (List[VersionStats]): ç‰ˆæœ¬åˆ—è¡¨
            
        Returns:
            Dict[str, Any]: åˆ†å¸ƒåˆ†æç»“æœ
        """
        analysis = {}
        
        for version in versions:
            total = version.total_chunks
            if total > 0:
                dist_percentages = {
                    'small_pct': (version.size_distribution.get('small', 0) / total) * 100,
                    'medium_pct': (version.size_distribution.get('medium', 0) / total) * 100,
                    'large_pct': (version.size_distribution.get('large', 0) / total) * 100,
                    'extra_large_pct': (version.size_distribution.get('extra_large', 0) / total) * 100
                }
                analysis[version.version] = dist_percentages
        
        return analysis
    
    def generate_report(self, v1_stats: VersionStats, v2_stats: VersionStats, v3_stats: VersionStats) -> str:
        """
        ç”Ÿæˆè¯¦ç»†å¯¹æ¯”æŠ¥å‘Š
        
        Args:
            v1_stats (VersionStats): V1ç»Ÿè®¡ä¿¡æ¯
            v2_stats (VersionStats): V2ç»Ÿè®¡ä¿¡æ¯
            v3_stats (VersionStats): V3ç»Ÿè®¡ä¿¡æ¯
            
        Returns:
            str: å¯¹æ¯”æŠ¥å‘Š
        """
        report = []
        report.append("=" * 80)
        report.append("ğŸ“Š é¢„å¤„ç†è„šæœ¬ç‰ˆæœ¬å¯¹æ¯”åˆ†ææŠ¥å‘Š")
        report.append("=" * 80)
        report.append("")
        
        # åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
        report.append("ğŸ“‹ åŸºæœ¬ä¿¡æ¯å¯¹æ¯”:")
        report.append("-" * 50)
        report.append(f"{'æŒ‡æ ‡':<20} {'V1':<15} {'V2':<15} {'V3':<15}")
        report.append("-" * 50)
        report.append(f"{'åˆ†å—æ€»æ•°':<20} {v1_stats.total_chunks:<15} {v2_stats.total_chunks:<15} {v3_stats.total_chunks:<15}")
        report.append(f"{'å¹³å‡åˆ†å—å¤§å°':<20} {v1_stats.avg_chunk_size:<15.0f} {v2_stats.avg_chunk_size:<15.0f} {v3_stats.avg_chunk_size:<15.0f}")
        report.append(f"{'å¹³å‡è´¨é‡åˆ†æ•°':<20} {v1_stats.avg_quality_score:<15.2f} {v2_stats.avg_quality_score:<15.2f} {v3_stats.avg_quality_score:<15.2f}")
        report.append(f"{'è¾¹ç•Œè´¨é‡åˆ†æ•°':<20} {v1_stats.boundary_quality_score:<15.2f} {v2_stats.boundary_quality_score:<15.2f} {v3_stats.boundary_quality_score:<15.2f}")
        report.append("")
        
        # V2ç›¸å¯¹V1çš„æ”¹è¿›
        v2_improvements = self.calculate_improvements(v1_stats, v2_stats)
        report.append("ğŸ“ˆ V2ç›¸å¯¹V1çš„æ”¹è¿›:")
        report.append("-" * 30)
        for metric, improvement in v2_improvements.items():
            report.append(f"{metric}: {improvement:+.1f}%")
        report.append("")
        
        # V3ç›¸å¯¹V1çš„æ”¹è¿›
        v3_improvements = self.calculate_improvements(v1_stats, v3_stats)
        report.append("ğŸ“ˆ V3ç›¸å¯¹V1çš„æ”¹è¿›:")
        report.append("-" * 30)
        for metric, improvement in v3_improvements.items():
            report.append(f"{metric}: {improvement:+.1f}%")
        report.append("")
        
        # V3ç›¸å¯¹V2çš„æ”¹è¿›
        v3_v2_improvements = self.calculate_improvements(v2_stats, v3_stats)
        report.append("ğŸ“ˆ V3ç›¸å¯¹V2çš„æ”¹è¿›:")
        report.append("-" * 30)
        for metric, improvement in v3_v2_improvements.items():
            report.append(f"{metric}: {improvement:+.1f}%")
        report.append("")
        
        # å¤§å°åˆ†å¸ƒåˆ†æ
        size_analysis = self.analyze_size_distribution([v1_stats, v2_stats, v3_stats])
        report.append("ğŸ“Š åˆ†å—å¤§å°åˆ†å¸ƒåˆ†æ:")
        report.append("-" * 50)
        report.append(f"{'å¤§å°ç±»åˆ«':<15} {'V1 (%)':<15} {'V2 (%)':<15} {'V3 (%)':<15}")
        report.append("-" * 50)
        
        categories = ['small_pct', 'medium_pct', 'large_pct', 'extra_large_pct']
        category_names = ['å°åˆ†å—(<400)', 'ä¸­åˆ†å—(400-800)', 'å¤§åˆ†å—(800-1500)', 'è¶…å¤§åˆ†å—(>1500)']
        
        for cat, name in zip(categories, category_names):
            v1_pct = size_analysis.get('V1', {}).get(cat, 0)
            v2_pct = size_analysis.get('V2', {}).get(cat, 0)
            v3_pct = size_analysis.get('V3', {}).get(cat, 0)
            report.append(f"{name:<15} {v1_pct:<15.1f} {v2_pct:<15.1f} {v3_pct:<15.1f}")
        report.append("")
        
        # æŠ€æœ¯ç‰¹æ€§å¯¹æ¯”
        report.append("ğŸ”§ æŠ€æœ¯ç‰¹æ€§å¯¹æ¯”:")
        report.append("-" * 30)
        report.append(f"V1: åŸºç¡€ç‰ˆæœ¬ï¼Œç®€å•è¾¹ç•Œæ£€æµ‹")
        report.append(f"V2: ä¼˜åŒ–è¾¹ç•Œæ£€æµ‹ï¼Œå¼ºåˆ¶åˆ†å‰²: {v2_stats.forced_splits}æ¬¡")
        report.append(f"V3: æœ€ç»ˆä¼˜åŒ–ï¼Œå¼ºåˆ¶åˆ†å‰²: {v3_stats.forced_splits}æ¬¡")
        report.append("")
        
        # å…³é”®å‘ç°
        report.append("ğŸ” å…³é”®å‘ç°:")
        report.append("-" * 20)
        
        # åˆ†å—æ•°é‡åˆ†æ
        if v3_stats.total_chunks > v1_stats.total_chunks * 2:
            report.append(f"âœ… V3æ˜¾è‘—å¢åŠ äº†åˆ†å—æ•°é‡ï¼Œä»{v1_stats.total_chunks}å¢åŠ åˆ°{v3_stats.total_chunks}")
        
        # åˆ†å—å¤§å°åˆ†æ
        if v3_stats.avg_chunk_size < v1_stats.avg_chunk_size:
            report.append(f"âœ… V3æˆåŠŸå‡å°äº†å¹³å‡åˆ†å—å¤§å°ï¼Œä»{v1_stats.avg_chunk_size:.0f}å‡å°‘åˆ°{v3_stats.avg_chunk_size:.0f}")
        
        # è¶…å¤§åˆ†å—æ§åˆ¶
        v1_extra_large = v1_stats.size_distribution.get('extra_large', 0)
        v3_extra_large = v3_stats.size_distribution.get('extra_large', 0)
        if v3_extra_large < v1_extra_large:
            report.append(f"âœ… V3æœ‰æ•ˆæ§åˆ¶äº†è¶…å¤§åˆ†å—ï¼Œä»{v1_extra_large}ä¸ªå‡å°‘åˆ°{v3_extra_large}ä¸ª")
        
        # è´¨é‡åˆ†æ•°åˆ†æ
        if v3_stats.avg_quality_score < v1_stats.avg_quality_score:
            report.append(f"âš ï¸  V3çš„è´¨é‡åˆ†æ•°è¾ƒä½ï¼Œå¯èƒ½æ˜¯ç”±äºå¼ºåˆ¶åˆ†å‰²å¯¼è‡´çš„")
        
        report.append("")
        
        # æ¨èå»ºè®®
        report.append("ğŸ’¡ æ¨èå»ºè®®:")
        report.append("-" * 20)
        
        if v3_stats.avg_chunk_size < 500:
            report.append("âœ… V3æˆåŠŸè¾¾åˆ°äº†ç›®æ ‡åˆ†å—å¤§å°ï¼ˆ400-600å­—ç¬¦ï¼‰")
        else:
            report.append("âš ï¸  å»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–åˆ†å—å¤§å°æ§åˆ¶")
        
        if v3_extra_large == 0:
            report.append("âœ… V3æˆåŠŸæ¶ˆé™¤äº†è¶…å¤§åˆ†å—é—®é¢˜")
        else:
            report.append(f"âš ï¸  ä»æœ‰{v3_extra_large}ä¸ªè¶…å¤§åˆ†å—éœ€è¦å¤„ç†")
        
        if v3_stats.boundary_quality_score < 0.5:
            report.append("âš ï¸  å»ºè®®ä¼˜åŒ–è¾¹ç•Œæ£€æµ‹ç®—æ³•ä»¥æé«˜è´¨é‡åˆ†æ•°")
        
        report.append("")
        report.append("=" * 80)
        report.append("ğŸ“ æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        report.append("=" * 80)
        
        return "\n".join(report)
    
    def save_report(self, report: str, output_path: str):
        """
        ä¿å­˜å¯¹æ¯”æŠ¥å‘Š
        
        Args:
            report (str): æŠ¥å‘Šå†…å®¹
            output_path (str): è¾“å‡ºè·¯å¾„
        """
        try:
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(report)
            
            print(f"ğŸ“„ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_path}")
            
        except Exception as e:
            print(f"âŒ ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")
            raise

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='é¢„å¤„ç†è„šæœ¬ç‰ˆæœ¬å¯¹æ¯”åˆ†æå·¥å…·')
    parser.add_argument('--v1-quality', required=True, help='V1è´¨é‡æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--v2-stats', required=True, help='V2ç»Ÿè®¡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--v3-stats', required=True, help='V3ç»Ÿè®¡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', required=True, help='è¾“å‡ºæŠ¥å‘Šè·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºå¯¹æ¯”å™¨
        comparator = VersionComparator()
        
        print("ğŸ“Š å¼€å§‹ç‰ˆæœ¬å¯¹æ¯”åˆ†æ...")
        
        # åŠ è½½æ•°æ®
        print("ğŸ“¥ åŠ è½½V1æ•°æ®...")
        v1_stats = comparator.load_v1_data(args.v1_quality)
        
        print("ğŸ“¥ åŠ è½½V2æ•°æ®...")
        v2_stats = comparator.load_v2_v3_data(args.v2_stats, "V2")
        
        print("ğŸ“¥ åŠ è½½V3æ•°æ®...")
        v3_stats = comparator.load_v2_v3_data(args.v3_stats, "V3")
        
        # ç”ŸæˆæŠ¥å‘Š
        print("ğŸ“ ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š...")
        report = comparator.generate_report(v1_stats, v2_stats, v3_stats)
        
        # ä¿å­˜æŠ¥å‘Š
        comparator.save_report(report, args.output)
        
        # æ‰“å°æ‘˜è¦
        print("\n" + "="*50)
        print("ğŸ“Š å¯¹æ¯”æ‘˜è¦:")
        print(f"V1: {v1_stats.total_chunks}ä¸ªåˆ†å—, å¹³å‡{v1_stats.avg_chunk_size:.0f}å­—ç¬¦")
        print(f"V2: {v2_stats.total_chunks}ä¸ªåˆ†å—, å¹³å‡{v2_stats.avg_chunk_size:.0f}å­—ç¬¦")
        print(f"V3: {v3_stats.total_chunks}ä¸ªåˆ†å—, å¹³å‡{v3_stats.avg_chunk_size:.0f}å­—ç¬¦")
        print("="*50)
        
        print("âœ… ç‰ˆæœ¬å¯¹æ¯”åˆ†æå®Œæˆ!")
        return 0
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main())