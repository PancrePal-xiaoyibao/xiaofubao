#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç‰ˆæœ¬å¯¹æ¯”åˆ†æè„šæœ¬
æ¯”è¾ƒpreprocess_enhanced.py (v1) å’Œ preprocess_enhanced_v2.py (v2) çš„å¤„ç†æ•ˆæœ

åŠŸèƒ½ï¼š
1. åŠ è½½ä¸¤ä¸ªç‰ˆæœ¬çš„å¤„ç†ç»“æœ
2. å¯¹æ¯”å…³é”®æŒ‡æ ‡
3. åˆ†ææ”¹è¿›æ•ˆæœ
4. ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š

ä½œè€…: RAGé¢„å¤„ç†ä¸“å®¶
ç‰ˆæœ¬: 1.0
"""

import json
import argparse
from typing import Dict, List, Any

class VersionComparator:
    """ç‰ˆæœ¬å¯¹æ¯”åˆ†æå™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¯¹æ¯”å™¨"""
        self.v1_quality = None
        self.v2_data = None
    
    def load_v1_results(self, quality_file: str):
        """
        åŠ è½½V1ç‰ˆæœ¬ç»“æœ
        
        Args:
            quality_file (str): V1è´¨é‡æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        try:
            # åŠ è½½è´¨é‡æŠ¥å‘Š
            with open(quality_file, 'r', encoding='utf-8') as f:
                self.v1_quality = json.load(f)
            
            print(f"âœ… V1ç»“æœåŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ V1ç»“æœåŠ è½½å¤±è´¥: {e}")
            raise
    
    def load_v2_results(self, stats_file: str):
        """
        åŠ è½½V2ç‰ˆæœ¬ç»“æœ
        
        Args:
            stats_file (str): V2ç»Ÿè®¡æ–‡ä»¶è·¯å¾„
        """
        try:
            with open(stats_file, 'r', encoding='utf-8') as f:
                self.v2_data = json.load(f)
            
            print(f"âœ… V2ç»“æœåŠ è½½æˆåŠŸ")
            
        except Exception as e:
            print(f"âŒ V2ç»“æœåŠ è½½å¤±è´¥: {e}")
            raise
    
    def extract_v1_metrics(self) -> Dict[str, Any]:
        """
        æå–V1ç‰ˆæœ¬å…³é”®æŒ‡æ ‡
        
        Returns:
            Dict[str, Any]: V1æŒ‡æ ‡å­—å…¸
        """
        if not self.v1_quality:
            return {}
        
        summary = self.v1_quality.get('summary', {})
        size_analysis = self.v1_quality.get('size_analysis', {})
        boundary_analysis = self.v1_quality.get('boundary_analysis', {})
        
        return {
            'total_chunks': summary.get('total_chunks', 0),
            'overall_quality_score': summary.get('overall_quality_score', 0),
            'total_issues': summary.get('total_issues', 0),
            'high_severity_issues': summary.get('high_severity_issues', 0),
            'average_chunk_size': size_analysis.get('average_size', 0),
            'median_chunk_size': size_analysis.get('median_size', 0),
            'boundary_quality_score': boundary_analysis.get('average_quality_score', 0),
            'large_chunks_count': size_analysis.get('distribution', {}).get('large', 0),
            'extra_large_chunks_count': size_analysis.get('distribution', {}).get('extra_large', 0)
        }
    
    def extract_v2_metrics(self) -> Dict[str, Any]:
        """
        æå–V2ç‰ˆæœ¬å…³é”®æŒ‡æ ‡
        
        Returns:
            Dict[str, Any]: V2æŒ‡æ ‡å­—å…¸
        """
        if not self.v2_data:
            return {}
        
        stats = self.v2_data.get('statistics', {})
        
        return {
            'total_chunks': stats.get('total_chunks', 0),
            'overall_quality_score': stats.get('average_quality_score', 0),
            'boundary_quality_score': stats.get('boundary_quality_score', 0),
            'average_chunk_size': stats.get('average_chunk_size', 0),
            'large_chunks_count': stats.get('size_distribution', {}).get('large', 0),
            'extra_large_chunks_count': stats.get('size_distribution', {}).get('extra_large', 0),
            'medium_chunks_count': stats.get('size_distribution', {}).get('medium', 0),
            'small_chunks_count': stats.get('size_distribution', {}).get('small', 0)
        }
    
    def calculate_improvements(self, v1_metrics: Dict[str, Any], v2_metrics: Dict[str, Any]) -> Dict[str, Any]:
        """
        è®¡ç®—æ”¹è¿›æ•ˆæœ
        
        Args:
            v1_metrics (Dict[str, Any]): V1æŒ‡æ ‡
            v2_metrics (Dict[str, Any]): V2æŒ‡æ ‡
            
        Returns:
            Dict[str, Any]: æ”¹è¿›æ•ˆæœå­—å…¸
        """
        improvements = {}
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡çš„å˜åŒ–
        for key in v1_metrics:
            if key in v2_metrics:
                v1_val = v1_metrics[key]
                v2_val = v2_metrics[key]
                
                if v1_val != 0:
                    change_percent = ((v2_val - v1_val) / v1_val) * 100
                    improvements[key] = {
                        'v1': v1_val,
                        'v2': v2_val,
                        'change': v2_val - v1_val,
                        'change_percent': round(change_percent, 2)
                    }
                else:
                    improvements[key] = {
                        'v1': v1_val,
                        'v2': v2_val,
                        'change': v2_val - v1_val,
                        'change_percent': 'N/A'
                    }
        
        return improvements
    
    def generate_report(self, output_file: str = None) -> str:
        """
        ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        
        Args:
            output_file (str): è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            str: æŠ¥å‘Šå†…å®¹
        """
        if not self.v1_quality or not self.v2_data:
            return "âŒ ç¼ºå°‘å¿…è¦çš„æ•°æ®ï¼Œæ— æ³•ç”ŸæˆæŠ¥å‘Š"
        
        # æå–æŒ‡æ ‡
        v1_metrics = self.extract_v1_metrics()
        v2_metrics = self.extract_v2_metrics()
        
        # è®¡ç®—æ”¹è¿›
        improvements = self.calculate_improvements(v1_metrics, v2_metrics)
        
        # ç”ŸæˆæŠ¥å‘Š
        report_lines = []
        report_lines.append("=" * 60)
        report_lines.append("ğŸ“Š é¢„å¤„ç†ç‰ˆæœ¬å¯¹æ¯”æŠ¥å‘Š")
        report_lines.append("=" * 60)
        report_lines.append("")
        
        # åŸºæœ¬ä¿¡æ¯å¯¹æ¯”
        report_lines.append("ğŸ“‹ åŸºæœ¬ä¿¡æ¯å¯¹æ¯”:")
        report_lines.append(f"  V1 æ€»åˆ†å—æ•°: {v1_metrics.get('total_chunks', 'N/A')}")
        report_lines.append(f"  V2 æ€»åˆ†å—æ•°: {v2_metrics.get('total_chunks', 'N/A')}")
        if 'total_chunks' in improvements:
            change = improvements['total_chunks']['change']
            change_pct = improvements['total_chunks']['change_percent']
            report_lines.append(f"  å˜åŒ–: {change:+d} ({change_pct:+.1f}%)")
        report_lines.append("")
        
        # è´¨é‡åˆ†æ•°å¯¹æ¯”
        report_lines.append("ğŸ¯ è´¨é‡åˆ†æ•°å¯¹æ¯”:")
        
        # æ•´ä½“è´¨é‡
        if 'overall_quality_score' in improvements:
            imp = improvements['overall_quality_score']
            report_lines.append(f"  æ•´ä½“è´¨é‡åˆ†æ•°: {imp['v1']:.2f} â†’ {imp['v2']:.2f} ({imp['change_percent']:+.1f}%)")
        
        # è¾¹ç•Œè´¨é‡
        if 'boundary_quality_score' in improvements:
            imp = improvements['boundary_quality_score']
            report_lines.append(f"  è¾¹ç•Œè´¨é‡åˆ†æ•°: {imp['v1']:.2f} â†’ {imp['v2']:.2f} ({imp['change_percent']:+.1f}%)")
        
        report_lines.append("")
        
        # åˆ†å—å¤§å°å¯¹æ¯”
        report_lines.append("ğŸ“ åˆ†å—å¤§å°å¯¹æ¯”:")
        if 'average_chunk_size' in improvements:
            imp = improvements['average_chunk_size']
            report_lines.append(f"  å¹³å‡åˆ†å—å¤§å°: {imp['v1']} â†’ {imp['v2']} å­—ç¬¦ ({imp['change_percent']:+.1f}%)")
        
        # è¶…å¤§åˆ†å—å¯¹æ¯”
        if 'extra_large_chunks_count' in improvements:
            imp = improvements['extra_large_chunks_count']
            report_lines.append(f"  è¶…å¤§åˆ†å—æ•°é‡: {imp['v1']} â†’ {imp['v2']} ({imp['change']:+d})")
        
        report_lines.append("")
        
        # é—®é¢˜åˆ†æ
        report_lines.append("âš ï¸ å‘ç°çš„é—®é¢˜:")
        
        if v2_metrics.get('total_chunks', 0) < 50:
            report_lines.append("  1. âŒ V2åˆ†å—æ•°é‡è¿‡å°‘ï¼Œå¯èƒ½å¯¼è‡´åˆ†å—è¿‡å¤§")
        
        if v2_metrics.get('extra_large_chunks_count', 0) > 0:
            report_lines.append(f"  2. âŒ V2ä»æœ‰{v2_metrics.get('extra_large_chunks_count', 0)}ä¸ªè¶…å¤§åˆ†å—")
        
        if v2_metrics.get('boundary_quality_score', 0) < 0.75:
            report_lines.append("  3. âš ï¸ V2è¾¹ç•Œè´¨é‡ä»éœ€æå‡")
        
        # æ”¹è¿›å»ºè®®
        report_lines.append("")
        report_lines.append("ğŸ’¡ æ”¹è¿›å»ºè®®:")
        report_lines.append("  1. é™ä½ç›®æ ‡åˆ†å—å¤§å°ï¼ˆå»ºè®®400-600å­—ç¬¦ï¼‰")
        report_lines.append("  2. å¼ºåˆ¶åˆ†å‰²è¶…è¿‡1500å­—ç¬¦çš„åˆ†å—")
        report_lines.append("  3. ä¼˜åŒ–æ•°å­—æ ‡é¢˜æ£€æµ‹çš„ç½®ä¿¡åº¦é˜ˆå€¼")
        report_lines.append("  4. å¢åŠ æ›´å¤šè¯­ä¹‰è¾¹ç•Œæ£€æµ‹è§„åˆ™")
        
        report_lines.append("")
        report_lines.append("=" * 60)
        
        report_content = "\n".join(report_lines)
        
        # ä¿å­˜æŠ¥å‘Š
        if output_file:
            try:
                with open(output_file, 'w', encoding='utf-8') as f:
                    f.write(report_content)
                print(f"ğŸ“„ å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜è‡³: {output_file}")
            except Exception as e:
                print(f"âŒ æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")
        
        return report_content

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç‰ˆæœ¬å¯¹æ¯”åˆ†æè„šæœ¬')
    parser.add_argument('--v1-quality', required=True, help='V1è´¨é‡æŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    parser.add_argument('--v2-stats', required=True, help='V2ç»Ÿè®¡æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', help='è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„')
    
    args = parser.parse_args()
    
    try:
        # åˆ›å»ºå¯¹æ¯”å™¨
        comparator = VersionComparator()
        
        # åŠ è½½æ•°æ®
        comparator.load_v1_results(args.v1_quality)
        comparator.load_v2_results(args.v2_stats)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = comparator.generate_report(args.output)
        
        # æ‰“å°æŠ¥å‘Š
        print(report)
        
        return 0
        
    except Exception as e:
        print(f"âŒ å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        return 1

if __name__ == "__main__":
    exit(main())