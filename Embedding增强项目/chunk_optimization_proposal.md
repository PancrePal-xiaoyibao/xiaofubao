# Chunkåˆ†å—é€»è¾‘ä¼˜åŒ–æ–¹æ¡ˆ

## å½“å‰åˆ†ææ€»ç»“

### ç°æœ‰åˆ†å—é€»è¾‘
1. **åˆ†å—è§¦å‘æ¡ä»¶**ï¼š
   - Markdown H1ã€H2æ ‡é¢˜
   - ä¸­æ–‡ä¸€çº§åºå·ï¼ˆä¸€ã€äºŒã€ä¸‰ã€ç­‰ï¼‰
   - ä¸­æ–‡å­åºå·ï¼ˆï¼ˆä¸€ï¼‰ã€ï¼ˆäºŒï¼‰ã€ç­‰ï¼‰ä¸è§¦å‘åˆ†å—

2. **å¤§å—åˆ†å‰²ç­–ç•¥**ï¼š
   - è¶…è¿‡max_chars_per_chunkæ—¶ä»åå¾€å‰å¯»æ‰¾åˆ†å‰²ç‚¹
   - ä¼˜å…ˆé€‰æ‹©H3+æ ‡é¢˜ï¼ˆéä¸­æ–‡å­åºå·ï¼‰æˆ–ç©ºè¡Œ
   - ç¡®ä¿åˆ†å‰²åç¬¬ä¸€éƒ¨åˆ†â‰¥min_chars_per_chunk

3. **åå¤„ç†**ï¼š
   - ä»…åˆå¹¶ä»¥"æ³¨é‡Š"å¼€å¤´çš„chunk

## ä¸»è¦é—®é¢˜

1. **è¿‡åº¦åˆ†å—**ï¼šH1ã€H2æ ‡é¢˜å¼ºåˆ¶åˆ†å—ï¼Œäº§ç”Ÿè¿‡å°chunk
2. **åˆå¹¶ç­–ç•¥å•ä¸€**ï¼šåªå¤„ç†"æ³¨é‡Š"chunkï¼Œç¼ºå°‘æ™ºèƒ½åˆå¹¶
3. **åˆ†å‰²ç‚¹æœ‰é™**ï¼šåªè€ƒè™‘æ ‡é¢˜å’Œç©ºè¡Œï¼Œå¿½ç•¥æ®µè½ã€åˆ—è¡¨ç­‰è¯­ä¹‰è¾¹ç•Œ
4. **ç¼ºå°‘å…¨å±€ä¼˜åŒ–**ï¼šçº¿æ€§å¤„ç†ï¼Œæ— åå¤„ç†å¹³è¡¡

## ä¼˜åŒ–æ–¹æ¡ˆ

### 1. æ™ºèƒ½åˆå¹¶ç­–ç•¥
```python
def smart_merge_chunks(chunks, min_chars_per_chunk, max_chars_per_chunk):
    """æ™ºèƒ½åˆå¹¶å°chunkï¼Œå‡å°‘æ€»æ•°é‡åŒæ—¶ä¿æŒè¯­ä¹‰å®Œæ•´æ€§"""
    merged_chunks = []
    i = 0
    
    while i < len(chunks):
        current_chunk = chunks[i]
        current_size = get_chunk_char_count(current_chunk)
        
        # å¦‚æœå½“å‰chunkå¤ªå°ï¼Œå°è¯•ä¸ä¸‹ä¸€ä¸ªåˆå¹¶
        if current_size < min_chars_per_chunk and i + 1 < len(chunks):
            next_chunk = chunks[i + 1]
            combined_size = current_size + get_chunk_char_count(next_chunk)
            
            # å¦‚æœåˆå¹¶åä¸è¶…è¿‡æœ€å¤§é™åˆ¶ï¼Œåˆ™åˆå¹¶
            if combined_size <= max_chars_per_chunk:
                merged_chunk = current_chunk + next_chunk
                merged_chunks.append(merged_chunk)
                i += 2  # è·³è¿‡ä¸‹ä¸€ä¸ªchunk
                continue
        
        merged_chunks.append(current_chunk)
        i += 1
    
    return merged_chunks
```

### 2. æ•°å­—æ ‡é¢˜å’Œå­æ ‡é¢˜ä¼˜åŒ–ç­–ç•¥

#### 2.1 æ•°å­—æ ‡é¢˜è¯†åˆ«ä¸åˆ†å—ä¼˜åŒ–
```python
def is_numeric_section(line):
    """
    è¯†åˆ«æ•°å­—ç« èŠ‚æ ‡é¢˜ï¼Œæ”¯æŒçº¯æ ¼å¼å’ŒMarkdownæ ¼å¼
    
    Args:
        line (str): è¦æ£€æŸ¥çš„æ–‡æœ¬è¡Œ
        
    Returns:
        bool: æ˜¯å¦ä¸ºæ•°å­—ç« èŠ‚æ ‡é¢˜
    """
    stripped = line.strip()
    if not stripped:
        return False
    
    # ç§»é™¤è¡Œå·æ ‡è®°ï¼ˆå¦‚<1007>ï¼‰
    cleaned = re.sub(r'^<\d+>', '', stripped)
    
    # æ£€æŸ¥çº¯æ•°å­—æ ¼å¼ï¼ˆå¦‚"11ç»´æŒæ²»ç–—"ï¼‰
    if re.match(r'^[0-9]+[^0-9]', cleaned):
        return True
    
    # æ£€æŸ¥Markdownæ ¼å¼ï¼ˆå¦‚"# 11ç»´æŒæ²»ç–—"ï¼‰
    if re.match(r'^#+\s*[0-9]+[^0-9]', cleaned):
        return True
    
    return False

def get_chunk_boundary_priority(line):
    """
    è·å–åˆ†å—è¾¹ç•Œçš„ä¼˜å…ˆçº§ï¼Œæ•°å­—æ ‡é¢˜å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§
    
    Args:
        line (str): è¦æ£€æŸ¥çš„æ–‡æœ¬è¡Œ
        
    Returns:
        int: ä¼˜å…ˆçº§ï¼ˆ1=æœ€é«˜ï¼Œ0=æ— ä¼˜å…ˆçº§ï¼‰
    """
    # æ•°å­—æ ‡é¢˜å…·æœ‰æœ€é«˜ä¼˜å…ˆçº§
    if is_numeric_section(line):
        return 1
    
    # ä¸­æ–‡ä¸€çº§åºå·
    if is_chinese_major_section(line):
        return 1
    
    # Markdown H1ã€H2æ ‡é¢˜
    heading_level = get_heading_level(line)
    if heading_level in [1, 2]:
        return 1
    
    # å­æ ‡é¢˜å…·æœ‰ä¸­ç­‰ä¼˜å…ˆçº§
    if is_subtitle(line):
        return 2
    
    return 0
```

#### 2.2 å­æ ‡é¢˜è¯†åˆ«ä¸åˆ†å—ç­–ç•¥
```python
def is_subtitle(line):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºå­æ ‡é¢˜ï¼Œæ”¯æŒå¤šç§æ ¼å¼
    
    Args:
        line (str): è¦æ£€æŸ¥çš„æ–‡æœ¬è¡Œ
        
    Returns:
        bool: æ˜¯å¦ä¸ºå­æ ‡é¢˜
    """
    stripped = line.strip()
    if not stripped:
        return False
    
    # Markdownå­æ ‡é¢˜ï¼ˆH3åŠä»¥ä¸‹ï¼‰
    if stripped.startswith('##') and not stripped.startswith('###'):
        return False  # H2ä¸ç®—å­æ ‡é¢˜
    if stripped.startswith('###'):
        return True
    
    # ä¸­æ–‡äºŒçº§åºå·ï¼ˆå¦‚"ï¼ˆä¸€ï¼‰"ã€"ï¼ˆäºŒï¼‰"ï¼‰
    if re.match(r'^ï¼ˆ[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ï¼‰', stripped):
        return True
    
    # æ•°å­—åºå·ï¼ˆå¦‚"(1)"ã€"(2)"ã€"1."ã€"1ã€"ï¼‰
    if re.match(r'^(\([1-9][0-9]*\)|ï¼ˆ[1-9][0-9]*ï¼‰|[1-9][0-9]*\.|[1-9][0-9]*ã€)', stripped):
        return True
    
    # å­—æ¯åºå·ï¼ˆå¦‚"a)"ã€"A."ï¼‰
    if re.match(r'^[a-zA-Z][.)ã€]', stripped):
        return True
    
    return False

def should_split_at_subtitle(current_chunk_size, subtitle_line, max_chunk_size, is_first_subtitle=False):
    """
    å†³å®šæ˜¯å¦åœ¨å­æ ‡é¢˜å¤„åˆ†å—
    
    Args:
        current_chunk_size (int): å½“å‰chunkçš„å­—ç¬¦æ•°
        subtitle_line (str): å­æ ‡é¢˜è¡Œå†…å®¹
        max_chunk_size (int): æœ€å¤§chunkå¤§å°
        is_first_subtitle (bool): æ˜¯å¦ä¸ºç¬¬ä¸€ä¸ªå­æ ‡é¢˜
        
    Returns:
        bool: æ˜¯å¦åº”è¯¥åˆ†å—
    """
    # ç¬¬ä¸€ä¸ªå­æ ‡é¢˜(1)ä¸åˆ†å—ï¼Œä¸ä¸»æ ‡é¢˜ä¿æŒåœ¨ä¸€èµ·
    if is_first_subtitle or re.match(r'^(\([1ï¼‘]\)|ï¼ˆ[1ï¼‘]ï¼‰|[1ï¼‘]\.|[1ï¼‘]ã€)', subtitle_line.strip()):
        return False
    
    # å¦‚æœå½“å‰chunkå¤§å°è¶…è¿‡80%é˜ˆå€¼ï¼Œåœ¨å­æ ‡é¢˜å¤„åˆ†å—
    if current_chunk_size > max_chunk_size * 0.8:
        return True
    
    return False

def detect_title_subtitle_relationship(lines, title_index):
    """
    æ£€æµ‹ä¸»æ ‡é¢˜ä¸å­æ ‡é¢˜çš„å…³ç³»
    
    Args:
        lines (list): æ‰€æœ‰æ–‡æ¡£è¡Œ
        title_index (int): ä¸»æ ‡é¢˜è¡Œçš„ç´¢å¼•
        
    Returns:
        tuple: (æ˜¯å¦æœ‰å­æ ‡é¢˜, ç¬¬ä¸€ä¸ªå­æ ‡é¢˜çš„ç´¢å¼•)
    """
    # æ£€æŸ¥åç»­5è¡Œå†…æ˜¯å¦æœ‰å­æ ‡é¢˜
    for i in range(title_index + 1, min(title_index + 6, len(lines))):
        line = lines[i].strip()
        if not line:
            continue
            
        # æ£€æµ‹å­æ ‡é¢˜æ ¼å¼
        if is_subtitle(line):
            return True, i
            
        # å¦‚æœé‡åˆ°å…¶ä»–ä¸»æ ‡é¢˜ï¼Œåœæ­¢æŸ¥æ‰¾
        if get_chunk_boundary_priority(line) >= 1:
            break
            
    return False, -1
```

#### 2.3 ä¸»æ ‡é¢˜ä¸å­æ ‡é¢˜çš„åˆ†å—ä¿æŠ¤ç­–ç•¥
```python
def protect_title_subtitle_cohesion(lines, chunk_boundaries):
    """
    ä¿æŠ¤ä¸»æ ‡é¢˜ä¸ç¬¬ä¸€ä¸ªå­æ ‡é¢˜çš„å…³è”æ€§
    
    Args:
        lines (list): æ‰€æœ‰æ–‡æ¡£è¡Œ
        chunk_boundaries (list): å½“å‰çš„åˆ†å—è¾¹ç•Œåˆ—è¡¨
        
    Returns:
        list: ä¼˜åŒ–åçš„åˆ†å—è¾¹ç•Œåˆ—è¡¨
    """
    protected_boundaries = []
    
    for boundary in chunk_boundaries:
        # æ£€æŸ¥è¾¹ç•Œæ˜¯å¦åœ¨ç¬¬ä¸€ä¸ªå­æ ‡é¢˜ä¹‹å‰
        if boundary < len(lines) and is_subtitle(lines[boundary]):
            # æ£€æŸ¥æ˜¯å¦ä¸ºç¬¬ä¸€ä¸ªå­æ ‡é¢˜
            if re.match(r'^(\([1ï¼‘]\)|ï¼ˆ[1ï¼‘]ï¼‰|[1ï¼‘]\.|[1ï¼‘]ã€)', lines[boundary].strip()):
                # å‘å‰æŸ¥æ‰¾ä¸»æ ‡é¢˜
                for i in range(boundary - 1, max(boundary - 6, 0), -1):
                    if get_chunk_boundary_priority(lines[i]) >= 1:
                        # æ‰¾åˆ°ä¸»æ ‡é¢˜ï¼Œä¸åœ¨ç¬¬ä¸€ä¸ªå­æ ‡é¢˜å‰åˆ†å—
                        continue
                
        protected_boundaries.append(boundary)
    
    return protected_boundaries

def optimize_subtitle_chunking(lines, max_chunk_size):
    """
    ä¼˜åŒ–å­æ ‡é¢˜åˆ†å—ç­–ç•¥
    
    Args:
        lines (list): æ‰€æœ‰æ–‡æ¡£è¡Œ
        max_chunk_size (int): æœ€å¤§chunkå¤§å°
        
    Returns:
        list: ä¼˜åŒ–åçš„åˆ†å—è¾¹ç•Œåˆ—è¡¨
    """
    boundaries = []
    current_chunk_size = 0
    in_title_subtitle_group = False
    first_subtitle_protected = False
    
    for i, line in enumerate(lines):
        line_size = len(line)
        current_chunk_size += line_size
        
        # æ£€æµ‹ä¸»æ ‡é¢˜
        if get_chunk_boundary_priority(line) >= 1:
            if current_chunk_size > 0:  # ä¸åœ¨å¼€å¤´æ—¶æ‰æ·»åŠ è¾¹ç•Œ
                boundaries.append(i)
                current_chunk_size = line_size
            in_title_subtitle_group = True
            first_subtitle_protected = False
            continue
        
        # æ£€æµ‹å­æ ‡é¢˜
        if is_subtitle(line):
            # ç¬¬ä¸€ä¸ªå­æ ‡é¢˜ä¸åˆ†å—
            if in_title_subtitle_group and not first_subtitle_protected:
                first_subtitle_protected = True
                continue
            
            # åç»­å­æ ‡é¢˜æ ¹æ®å¤§å°å†³å®šæ˜¯å¦åˆ†å—
            if should_split_at_subtitle(current_chunk_size, line, max_chunk_size):
                boundaries.append(i)
                current_chunk_size = line_size
                continue
        
        # é‡ç½®æ ‡é¢˜ç»„çŠ¶æ€
        if line.strip() and not is_subtitle(line):
            in_title_subtitle_group = False
    
    return boundaries
```

### 4. åŠ¨æ€åˆ†å—é˜ˆå€¼
```python
def should_start_new_chunk(line, current_chunk_lines, max_chars_per_chunk):
    """åŠ¨æ€å†³å®šæ˜¯å¦å¼€å§‹æ–°chunkï¼Œè€ƒè™‘å½“å‰chunkå¤§å°"""
    heading_level = get_heading_level(line)
    is_major_section = is_chinese_major_section(line)
    current_size = get_chunk_char_count(current_chunk_lines)
    
    # å¦‚æœå½“å‰chunkå¾ˆå°ï¼Œå³ä½¿é‡åˆ°ä¸»è¦æ ‡é¢˜ä¹Ÿä¸åˆ†å—
    if current_size < max_chars_per_chunk * 0.3:  # 30%é˜ˆå€¼
        return False
    
    # åŸæœ‰çš„åˆ†å—é€»è¾‘
    if heading_level in [1, 2] or is_major_section:
        return True
    
    return False
```

### 5. å¢å¼ºåˆ†å‰²ç‚¹æ£€æµ‹
```python
def find_better_split_point(chunk_lines, min_chars_per_chunk):
    """å¯»æ‰¾æ›´å¥½çš„åˆ†å‰²ç‚¹ï¼ŒåŒ…æ‹¬æ®µè½è¾¹ç•Œã€åˆ—è¡¨é¡¹ç­‰"""
    for i in range(len(chunk_lines) - 1, 0, -1):
        first_part_chars = get_chunk_char_count(chunk_lines[:i+1])
        if first_part_chars >= min_chars_per_chunk:
            line = chunk_lines[i].strip()
            
            # ä¼˜å…ˆçº§1: H3+æ ‡é¢˜ï¼ˆéä¸­æ–‡å­åºå·ï¼‰
            if get_heading_level(chunk_lines[i]) >= 3 and not is_chinese_sub_section(chunk_lines[i]):
                return i + 1
            
            # ä¼˜å…ˆçº§2: ç©ºè¡Œ
            if not line:
                return i + 1
            
            # ä¼˜å…ˆçº§3: æ®µè½ç»“æŸï¼ˆå¥å·ã€æ„Ÿå¹å·ã€é—®å·ç»“å°¾ï¼‰
            if line.endswith(('ã€‚', 'ï¼', 'ï¼Ÿ', '.', '!', '?')):
                return i + 1
            
            # ä¼˜å…ˆçº§4: åˆ—è¡¨é¡¹å¼€å§‹
            next_line = chunk_lines[i + 1].strip() if i + 1 < len(chunk_lines) else ""
            if next_line.startswith(('- ', '* ', '+ ', '1. ', '2. ')):
                return i + 1
    
    return -1
```

### 6. è¡¨æ ¼æ ‡é¢˜ä¸å†…å®¹ä¿æŒä¸€è‡´çš„åˆ†å—è§„åˆ™

#### 4.1 é—®é¢˜æè¿°
å½“å‰çš„åˆ†å—é€»è¾‘å­˜åœ¨ä¸€ä¸ªä¸¥é‡é—®é¢˜ï¼šä»¥å†’å·ç»“å°¾çš„æ ‡é¢˜ï¼ˆå¦‚"ä¹³è…ºç™Œå†…åˆ†æ³Œè¯ç‰©ç”¨æ³•åŠç”¨é‡ï¼š"ï¼‰ä¸å…¶åç»­çš„è¡¨æ ¼å†…å®¹è¢«åˆ†ç¦»åˆ°ä¸åŒçš„chunkä¸­ã€‚è¿™ç ´åäº†å†…å®¹çš„è¯­ä¹‰å®Œæ•´æ€§ï¼Œå½±å“äº†æ–‡æ¡£çš„å¯è¯»æ€§å’Œæ£€ç´¢æ•ˆæœã€‚

#### 4.2 æ ¸å¿ƒåŸåˆ™
- **æ ‡é¢˜+å†’å·ä¸åç»­å†…å®¹çš„å…³è”æ€§**ï¼šä»¥å†’å·ï¼ˆï¼šï¼‰ç»“å°¾çš„æ ‡é¢˜è¡Œåº”è¯¥ä¸å…¶åç»­çš„ç›¸å…³å†…å®¹ä¿æŒåœ¨åŒä¸€ä¸ªchunkä¸­
- **å†…å®¹å…³è”æ€§åˆ¤æ–­æ ‡å‡†**ï¼š
  - ç›´æ¥å…³è”ï¼šæ ‡é¢˜åç´§è·Ÿçš„ç¼–å·åˆ—è¡¨ï¼ˆå¦‚ï¼ˆ1ï¼‰ã€ï¼ˆ2ï¼‰ç­‰ï¼‰
  - é—´æ¥å…³è”ï¼šæ ‡é¢˜åçš„ç©ºè¡Œ+ç¼–å·åˆ—è¡¨
  - è¡¨æ ¼å†…å®¹ï¼šæ ‡é¢˜åçš„ç»“æ„åŒ–æ•°æ®

#### 4.3 å®ç°è§„åˆ™
```python
def is_title_with_colon(line):
    """
    è¯†åˆ«ä»¥å†’å·ç»“å°¾çš„æ ‡é¢˜è¡Œ
    
    Args:
        line (str): è¦æ£€æŸ¥çš„æ–‡æœ¬è¡Œ
        
    Returns:
        bool: æ˜¯å¦ä¸ºä»¥å†’å·ç»“å°¾çš„æ ‡é¢˜
    """
    stripped = line.strip()
    if not stripped:
        return False
    
    # æ£€æŸ¥æ˜¯å¦ä»¥ä¸­æ–‡å†’å·æˆ–è‹±æ–‡å†’å·ç»“å°¾
    if stripped.endswith('ï¼š') or stripped.endswith(':'):
        # æ’é™¤çº¯æ•°å­—+å†’å·çš„æƒ…å†µï¼ˆå¯èƒ½æ˜¯æ—¶é—´ï¼‰
        if not re.match(r'^\d+[ï¼š:]$', stripped):
            return True
    
    return False

def has_related_content_after_title(lines, title_index, max_look_ahead=5):
    """
    åˆ¤æ–­æ ‡é¢˜åæ˜¯å¦æœ‰ç›¸å…³çš„åˆ—è¡¨æˆ–è¡¨æ ¼å†…å®¹
    
    Args:
        lines (list): æ‰€æœ‰æ–‡æ¡£è¡Œ
        title_index (int): æ ‡é¢˜è¡Œçš„ç´¢å¼•
        max_look_ahead (int): å‘å‰æŸ¥çœ‹çš„æœ€å¤§è¡Œæ•°
        
    Returns:
        bool: æ˜¯å¦æœ‰ç›¸å…³å†…å®¹
    """
    for i in range(title_index + 1, min(title_index + max_look_ahead + 1, len(lines))):
        line = lines[i].strip()
        
        # è·³è¿‡ç©ºè¡Œ
        if not line:
            continue
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºç¼–å·åˆ—è¡¨é¡¹
        if re.match(r'^[ï¼ˆ(]\d+[ï¼‰)]', line) or re.match(r'^\d+[.ã€]', line):
            return True
            
        # æ£€æŸ¥æ˜¯å¦ä¸ºå…¶ä»–åˆ—è¡¨æ ¼å¼
        if line.startswith('- ') or line.startswith('* ') or line.startswith('+ '):
            return True
            
        # å¦‚æœé‡åˆ°å…¶ä»–æ ‡é¢˜ï¼Œåœæ­¢æŸ¥æ‰¾
        if get_chunk_boundary_priority(line) > 0:
            break
            
    return False

def should_start_new_chunk_with_title_cohesion(line, current_chunk_lines, max_chars_per_chunk, all_lines=None, current_index=None):
    """
    è€ƒè™‘æ ‡é¢˜ä¸å†…å®¹å…³è”æ€§çš„åˆ†å—å†³ç­–å‡½æ•°
    
    Args:
        line (str): å½“å‰å¤„ç†çš„è¡Œ
        current_chunk_lines (list): å½“å‰chunkçš„è¡Œåˆ—è¡¨
        max_chars_per_chunk (int): æœ€å¤§å­—ç¬¦æ•°é™åˆ¶
        all_lines (list): æ‰€æœ‰æ–‡æ¡£è¡Œ
        current_index (int): å½“å‰è¡Œåœ¨all_linesä¸­çš„ç´¢å¼•
        
    Returns:
        bool: æ˜¯å¦åº”è¯¥å¼€å§‹æ–°chunk
    """
    # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦ä¸ºç›¸å…³å†…å®¹ï¼Œå‘å‰æŸ¥æ‰¾æ ‡é¢˜+å†’å·
    if all_lines and current_index is not None and is_related_to_title(line):
        # å‘å‰æŸ¥æ‰¾æœ€å¤š5è¡Œï¼Œå¯»æ‰¾æ ‡é¢˜+å†’å·
        for i in range(max(0, current_index - 5), current_index):
            if is_title_with_colon(all_lines[i]):
                return False  # ä¸åˆ†å—ï¼Œä¿æŒä¸æ ‡é¢˜åœ¨ä¸€èµ·
            # å¦‚æœé‡åˆ°å…¶ä»–é‡è¦è¾¹ç•Œï¼Œåœæ­¢æŸ¥æ‰¾
            if get_chunk_boundary_priority(all_lines[i]) >= 1:
                break
    
    # æ£€æŸ¥å½“å‰è¡Œæ˜¯å¦ä¸ºä»¥å†’å·ç»“å°¾çš„æ ‡é¢˜
    if is_title_with_colon(line) and all_lines and current_index is not None:
        # å¦‚æœåç»­æœ‰ç›¸å…³å†…å®¹ï¼Œå½“å‰ä¸åˆ†å—ï¼ˆè®©æ ‡é¢˜å’Œå†…å®¹åœ¨ä¸€èµ·ï¼‰
        if has_related_content_after_title(all_lines, current_index):
            return False
    
    # åŸæœ‰çš„åˆ†å—é€»è¾‘
    return original_should_start_new_chunk(line, current_chunk_lines, max_chars_per_chunk, all_lines, current_index)
```

#### 4.4 æµ‹è¯•ç”¨ä¾‹
- **åŸºæœ¬æ ‡é¢˜+åˆ—è¡¨æµ‹è¯•**ï¼šä¹³è…ºç™Œå†…åˆ†æ³Œè¯ç‰©ç”¨æ³•åŠç”¨é‡ï¼š+ ç¼–å·åˆ—è¡¨
- **æ ‡é¢˜+ç©ºè¡Œ+åˆ—è¡¨æµ‹è¯•**ï¼šæ²»ç–—æ–¹æ¡ˆï¼š+ ç©ºè¡Œ + ç¼–å·åˆ—è¡¨
- **å¤šçº§æ ‡é¢˜æµ‹è¯•**ï¼šä¸»è¦æ²»ç–—æ–¹æ¡ˆï¼š+ å­æ ‡é¢˜ + åˆ—è¡¨

#### 4.5 é¢„æœŸæ•ˆæœ
1. **è¯­ä¹‰å®Œæ•´æ€§**ï¼šæ ‡é¢˜ä¸å…¶è¯´æ˜å†…å®¹ä¿æŒåœ¨åŒä¸€chunkä¸­
2. **æ£€ç´¢å‡†ç¡®æ€§**ï¼šæé«˜ç›¸å…³å†…å®¹çš„æ£€ç´¢æ•ˆæœ
3. **å¯è¯»æ€§æå‡**ï¼šä¿æŒæ–‡æ¡£ç»“æ„çš„é€»è¾‘æ€§
4. **åˆ†å—è´¨é‡**ï¼šå‡å°‘ä¸åˆç†çš„åˆ†å—è¾¹ç•Œ

### 7. åå¤„ç†ä¼˜åŒ–
```python
def post_process_chunks(chunks, min_chars_per_chunk, max_chars_per_chunk):
    """åå¤„ç†ä¼˜åŒ–ï¼šå¹³è¡¡chunkå¤§å°ï¼Œå‡å°‘æ€»æ•°é‡"""
    # ç¬¬ä¸€æ­¥ï¼šæ™ºèƒ½åˆå¹¶å°chunk
    chunks = smart_merge_chunks(chunks, min_chars_per_chunk, max_chars_per_chunk)
    
    # ç¬¬äºŒæ­¥ï¼šå¤„ç†è¿‡å¤§çš„chunk
    optimized_chunks = []
    for chunk in chunks:
        if get_chunk_char_count(chunk) > max_chars_per_chunk * 1.2:  # 20%å®¹å¿åº¦
            # é‡æ–°åˆ†å‰²è¿‡å¤§çš„chunk
            split_chunks = split_large_chunk(chunk, min_chars_per_chunk, max_chars_per_chunk)
            optimized_chunks.extend(split_chunks)
        else:
            optimized_chunks.append(chunk)
    
    return optimized_chunks
```

## é¢„æœŸæ•ˆæœ

1. **å‡å°‘chunkæ•°é‡**ï¼šé€šè¿‡æ™ºèƒ½åˆå¹¶ï¼Œé¢„è®¡å‡å°‘15-25%çš„chunkæ•°é‡
2. **æé«˜å¹³å‡å¤§å°**ï¼šæ›´æ¥è¿‘target_chunk_sizeé…ç½®å€¼
3. **ä¿æŒè¯­ä¹‰å®Œæ•´æ€§**ï¼šæ”¹è¿›çš„åˆ†å‰²ç‚¹æ£€æµ‹ç¡®ä¿è¯­ä¹‰è¾¹ç•Œ
4. **æ›´å¥½çš„å¤§å°åˆ†å¸ƒ**ï¼šå‡å°‘è¿‡å°å’Œè¿‡å¤§çš„chunk

## å®æ–½æ­¥éª¤

1. **ç¬¬ä¸€é˜¶æ®µ**ï¼šå®ç°æ™ºèƒ½åˆå¹¶ç­–ç•¥
2. **ç¬¬äºŒé˜¶æ®µ**ï¼šæ·»åŠ åŠ¨æ€åˆ†å—é˜ˆå€¼
3. **ç¬¬ä¸‰é˜¶æ®µ**ï¼šå¢å¼ºåˆ†å‰²ç‚¹æ£€æµ‹
4. **ç¬¬å››é˜¶æ®µ**ï¼šé›†æˆåå¤„ç†ä¼˜åŒ–
5. **æµ‹è¯•éªŒè¯**ï¼šä½¿ç”¨ç°æœ‰æ–‡æ¡£éªŒè¯æ•ˆæœ

## 8. è¾¹ç•Œæ£€æµ‹å’Œä¿®å¤ç­–ç•¥

### 8.1 è¾¹ç•Œä½ç½®é”™è¯¯æ£€æµ‹

åŸºäºå‘ç°çš„é—®é¢˜ï¼ˆå¦‚ä¹³è…ºç™Œè¯Šç–—æŒ‡å—ç¬¬2215-2221è¡Œï¼‰ï¼Œéœ€è¦å®ç°è¾¹ç•Œä½ç½®é”™è¯¯çš„è‡ªåŠ¨æ£€æµ‹å’Œä¿®å¤ï¼š

```python
def detect_boundary_position_errors(chunks, original_lines):
    """
    æ£€æµ‹è¾¹ç•Œä½ç½®é”™è¯¯
    
    è¿”å›:
    - list: é”™è¯¯è¾¹ç•Œä½ç½®åˆ—è¡¨
    """
    errors = []
    
    for i, chunk in enumerate(chunks):
        chunk_start_line = get_chunk_start_line(chunk, original_lines)
        
        # æ£€æŸ¥è¾¹ç•Œæ˜¯å¦æ”¾åœ¨äº†ä½ä¼˜å…ˆçº§ä½ç½®
        if chunk_start_line > 0:
            boundary_line = original_lines[chunk_start_line - 1]
            current_line = original_lines[chunk_start_line]
            
            # æ£€æŸ¥æ˜¯å¦åœ¨Markdownæ ‡é¢˜å‰é”™è¯¯æ”¾ç½®è¾¹ç•Œ
            if (is_markdown_heading(current_line) and 
                not is_chinese_major_section(current_line)):
                
                # æŸ¥æ‰¾é™„è¿‘æ˜¯å¦æœ‰æ›´é«˜ä¼˜å…ˆçº§çš„åˆ†å—ç‚¹
                nearby_chinese_section = find_nearby_chinese_section(
                    chunk_start_line, original_lines, search_range=10
                )
                
                if nearby_chinese_section:
                    errors.append({
                        'chunk_index': i,
                        'error_line': chunk_start_line,
                        'error_type': 'boundary_before_markdown_heading',
                        'suggested_line': nearby_chinese_section['line_index'],
                        'description': f'è¾¹ç•Œåº”æ”¾åœ¨ä¸­æ–‡åºå·"{nearby_chinese_section["content"]}"ä¹‹å‰'
                    })
    
    return errors

def find_nearby_chinese_section(line_index, original_lines, search_range=10):
    """
    åœ¨æŒ‡å®šèŒƒå›´å†…æŸ¥æ‰¾ä¸­æ–‡ä¸€çº§åºå·
    """
    start = max(0, line_index - search_range)
    end = min(len(original_lines), line_index + search_range)
    
    for i in range(start, end):
        line = original_lines[i].strip()
        if is_chinese_major_section(line):
            return {
                'line_index': i,
                'content': line,
                'priority': get_chunk_boundary_priority(line)
            }
    
    return None
```

### 8.2 ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜å…³ç³»æ£€æµ‹ä¸ä¿®å¤

é’ˆå¯¹ä¸»æ ‡é¢˜ä¸ç´§é‚»å­æ ‡é¢˜è¢«è¾¹ç•Œæ ‡è®°é”™è¯¯åˆ†å¼€çš„é—®é¢˜ï¼Œå®ç°ä¸“é—¨çš„æ£€æµ‹å’Œä¿®å¤æœºåˆ¶ï¼š

```python
def detect_title_subtitle_separation_errors(file_path):
    """
    æ£€æµ‹ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜è¢«è¾¹ç•Œæ ‡è®°é”™è¯¯åˆ†å¼€çš„é—®é¢˜
    
    Args:
        file_path: å¤„ç†åçš„æ–‡æ¡£è·¯å¾„
        
    Returns:
        dict: åŒ…å«æ£€æµ‹ç»“æœçš„è¯¦ç»†æŠ¥å‘Š
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    main_titles = []
    separation_errors = []
    
    # æŸ¥æ‰¾æ‰€æœ‰ä¸»æ ‡é¢˜
    for i, line in enumerate(lines):
        line = line.strip()
        if (line.startswith('#') and not line.startswith('##')) or \
           re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€', line):
            main_titles.append((i, line))
    
    # æ£€æŸ¥æ¯ä¸ªä¸»æ ‡é¢˜ä¸ç´§é‚»å­æ ‡é¢˜çš„å…³ç³»
    for title_idx, title_content in main_titles:
        # æ£€æŸ¥åç»­5è¡Œ
        for j in range(title_idx + 1, min(title_idx + 6, len(lines))):
            next_line = lines[j].strip()
            
            # å¦‚æœé‡åˆ°è¾¹ç•Œæ ‡è®°
            if '[CHUNK_BOUNDARY]' in next_line:
                # æ£€æŸ¥è¾¹ç•Œæ ‡è®°åæ˜¯å¦ç´§è·Ÿå­æ ‡é¢˜
                if j + 1 < len(lines):
                    after_boundary = lines[j + 1].strip()
                    if is_subtitle(after_boundary):
                        separation_errors.append({
                            'main_title_line': title_idx + 1,
                            'main_title': title_content,
                            'boundary_line': j + 1,
                            'subtitle_line': j + 2,
                            'subtitle': after_boundary,
                            'error_type': 'main_title_subtitle_separated'
                        })
                break
                
            # å¦‚æœé‡åˆ°å­æ ‡é¢˜ä½†æ²¡æœ‰è¾¹ç•Œæ ‡è®°ï¼Œè¿™æ˜¯æ­£ç¡®çš„
            if is_subtitle(next_line):
                break
    
    return {
        'total_main_titles': len(main_titles),
        'separation_errors': separation_errors,
        'errors_count': len(separation_errors),
        'success_rate': (len(main_titles) - len(separation_errors)) / len(main_titles) * 100 if main_titles else 100
    }

def is_subtitle(line):
    """
    åˆ¤æ–­æ˜¯å¦ä¸ºå­æ ‡é¢˜
    
    Args:
        line: æ–‡æœ¬è¡Œ
        
    Returns:
        bool: æ˜¯å¦ä¸ºå­æ ‡é¢˜
    """
    line = line.strip()
    return (line.startswith('##') or  # Markdownå­æ ‡é¢˜
            re.match(r'^ï¼ˆ[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ï¼‰', line) or  # ä¸­æ–‡äºŒçº§åºå·
            re.match(r'^\d+\.', line) or  # æ•°å­—åºå·
            re.match(r'^[a-zA-Z]\)', line))  # å­—æ¯åºå·

def has_immediate_sub_heading(lines, current_index):
    """
    æ£€æµ‹ä¸»æ ‡é¢˜åæ˜¯å¦ç´§è·Ÿå­æ ‡é¢˜
    
    Args:
        lines: æ–‡æ¡£è¡Œåˆ—è¡¨
        current_index: å½“å‰ä¸»æ ‡é¢˜çš„è¡Œç´¢å¼•
        
    Returns:
        bool: å¦‚æœç´§è·Ÿå­æ ‡é¢˜è¿”å›Trueï¼Œå¦åˆ™è¿”å›False
    """
    # æ£€æŸ¥åç»­5è¡Œå†…å®¹
    for i in range(current_index + 1, min(current_index + 6, len(lines))):
        line = lines[i].strip()
        if not line:  # è·³è¿‡ç©ºè¡Œ
            continue
            
        # æ£€æµ‹å„ç§å­æ ‡é¢˜æ¨¡å¼
        if is_subtitle(line):
            return True
            
        # å¦‚æœé‡åˆ°å…¶ä»–å†…å®¹ï¼Œåœæ­¢æ£€æµ‹
        if line and not line.startswith('#'):
            break
            
    return False

def fix_title_subtitle_separation(chunks, original_lines):
    """
    ä¿®å¤ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜è¢«é”™è¯¯åˆ†å¼€çš„é—®é¢˜
    
    Args:
        chunks: å½“å‰åˆ†å—åˆ—è¡¨
        original_lines: åŸå§‹æ–‡æ¡£è¡Œåˆ—è¡¨
        
    Returns:
        list: ä¿®å¤åçš„åˆ†å—åˆ—è¡¨
    """
    fixed_chunks = []
    i = 0
    
    while i < len(chunks):
        current_chunk = chunks[i]
        
        # æ£€æŸ¥å½“å‰chunkçš„æœ€åä¸€è¡Œæ˜¯å¦ä¸ºä¸»æ ‡é¢˜
        last_line = current_chunk[-1].strip() if current_chunk else ""
        
        if (last_line.startswith('#') and not last_line.startswith('##')) or \
           re.match(r'^[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€', last_line):
            
            # æ£€æŸ¥ä¸‹ä¸€ä¸ªchunkçš„ç¬¬ä¸€è¡Œæ˜¯å¦ä¸ºå­æ ‡é¢˜
            if i + 1 < len(chunks):
                next_chunk = chunks[i + 1]
                first_line = next_chunk[0].strip() if next_chunk else ""
                
                if is_subtitle(first_line):
                    # åˆå¹¶è¿™ä¸¤ä¸ªchunk
                    merged_chunk = current_chunk + next_chunk
                    fixed_chunks.append(merged_chunk)
                    i += 2  # è·³è¿‡ä¸‹ä¸€ä¸ªchunk
                    continue
        
        fixed_chunks.append(current_chunk)
        i += 1
    
    return fixed_chunks
```

### 8.4 è‡ªåŠ¨åŒ–æ£€æµ‹å’Œä¿®å¤æµç¨‹

```python
def automated_boundary_detection_and_fix(file_path):
    """
    è‡ªåŠ¨åŒ–è¾¹ç•Œæ£€æµ‹å’Œä¿®å¤æµç¨‹
    
    Args:
        file_path: å¤„ç†åçš„æ–‡æ¡£è·¯å¾„
        
    Returns:
        dict: æ£€æµ‹å’Œä¿®å¤ç»“æœæŠ¥å‘Š
    """
    # ç¬¬ä¸€æ­¥ï¼šæ£€æµ‹ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜åˆ†ç¦»é”™è¯¯
    title_subtitle_report = detect_title_subtitle_separation_errors(file_path)
    
    # ç¬¬äºŒæ­¥ï¼šæ£€æµ‹è¾¹ç•Œä½ç½®é”™è¯¯
    with open(file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    boundary_errors = detect_boundary_position_errors(None, lines)
    
    # ç¬¬ä¸‰æ­¥ï¼šç”Ÿæˆç»¼åˆæŠ¥å‘Š
    report = {
        'file_path': file_path,
        'total_lines': len(lines),
        'total_boundaries': len([line for line in lines if '[CHUNK_BOUNDARY]' in line]),
        'title_subtitle_errors': title_subtitle_report,
        'boundary_position_errors': boundary_errors,
        'overall_quality_score': calculate_boundary_quality_score(title_subtitle_report, boundary_errors),
        'recommendations': generate_fix_recommendations(title_subtitle_report, boundary_errors)
    }
    
    return report

def calculate_boundary_quality_score(title_subtitle_report, boundary_errors):
    """
    è®¡ç®—è¾¹ç•Œè´¨é‡åˆ†æ•°
    
    Args:
        title_subtitle_report: ä¸»æ ‡é¢˜å­æ ‡é¢˜æ£€æµ‹æŠ¥å‘Š
        boundary_errors: è¾¹ç•Œä½ç½®é”™è¯¯åˆ—è¡¨
        
    Returns:
        float: è´¨é‡åˆ†æ•° (0-100)
    """
    total_issues = title_subtitle_report['errors_count'] + len(boundary_errors)
    total_boundaries = title_subtitle_report['total_main_titles']
    
    if total_boundaries == 0:
        return 100.0
    
    error_rate = total_issues / total_boundaries
    quality_score = max(0, 100 - (error_rate * 100))
    
    return round(quality_score, 2)

def generate_fix_recommendations(title_subtitle_report, boundary_errors):
    """
    ç”Ÿæˆä¿®å¤å»ºè®®
    
    Args:
        title_subtitle_report: ä¸»æ ‡é¢˜å­æ ‡é¢˜æ£€æµ‹æŠ¥å‘Š
        boundary_errors: è¾¹ç•Œä½ç½®é”™è¯¯åˆ—è¡¨
        
    Returns:
        list: ä¿®å¤å»ºè®®åˆ—è¡¨
    """
    recommendations = []
    
    if title_subtitle_report['errors_count'] > 0:
        recommendations.append({
            'type': 'title_subtitle_separation',
            'priority': 'high',
            'description': f'å‘ç°{title_subtitle_report["errors_count"]}ä¸ªä¸»æ ‡é¢˜ä¸å­æ ‡é¢˜è¢«é”™è¯¯åˆ†å¼€çš„é—®é¢˜',
            'action': 'ä½¿ç”¨has_immediate_sub_heading()å‡½æ•°ä¼˜åŒ–åˆ†å—é€»è¾‘'
        })
    
    if len(boundary_errors) > 0:
        recommendations.append({
            'type': 'boundary_position',
            'priority': 'medium',
            'description': f'å‘ç°{len(boundary_errors)}ä¸ªè¾¹ç•Œä½ç½®é”™è¯¯',
            'action': 'è°ƒæ•´è¾¹ç•Œä¼˜å…ˆçº§ç®—æ³•ï¼Œä¼˜å…ˆé€‰æ‹©ä¸­æ–‡åºå·ä½œä¸ºåˆ†å—ç‚¹'
        })
    
    return recommendations
```

### 8.5 è‡ªåŠ¨è¾¹ç•Œä¿®å¤

```python
def auto_fix_boundary_errors(chunks, original_lines, errors):
    """
    è‡ªåŠ¨ä¿®å¤è¾¹ç•Œä½ç½®é”™è¯¯
    
    å‚æ•°:
    - chunks: åŸå§‹chunkåˆ—è¡¨
    - original_lines: åŸå§‹æ–‡æ¡£è¡Œåˆ—è¡¨
    - errors: æ£€æµ‹åˆ°çš„é”™è¯¯åˆ—è¡¨
    
    è¿”å›:
    - list: ä¿®å¤åçš„chunkåˆ—è¡¨
    """
    if not errors:
        return chunks
    
    # æŒ‰è¡Œå·å€’åºæ’åºï¼Œé¿å…ä¿®å¤æ—¶ç´¢å¼•å˜åŒ–
    errors.sort(key=lambda x: x['error_line'], reverse=True)
    
    fixed_chunks = chunks.copy()
    
    for error in errors:
        chunk_index = error['chunk_index']
        suggested_line = error['suggested_line']
        
        # é‡æ–°åˆ†å‰²å—å½±å“çš„chunk
        if chunk_index < len(fixed_chunks):
            current_chunk = fixed_chunks[chunk_index]
            
            # æ‰¾åˆ°æ–°çš„åˆ†å‰²ç‚¹
            new_chunks = resplit_chunk_at_line(
                current_chunk, suggested_line, original_lines
            )
            
            # æ›¿æ¢åŸchunk
            fixed_chunks[chunk_index:chunk_index+1] = new_chunks
    
    return fixed_chunks

def resplit_chunk_at_line(chunk, split_line_index, original_lines):
    """
    åœ¨æŒ‡å®šè¡Œé‡æ–°åˆ†å‰²chunk
    """
    chunk_start = get_chunk_start_line(chunk, original_lines)
    chunk_end = get_chunk_end_line(chunk, original_lines)
    
    if chunk_start <= split_line_index <= chunk_end:
        # åˆ†å‰²ä¸ºä¸¤ä¸ªchunk
        first_chunk = original_lines[chunk_start:split_line_index]
        second_chunk = original_lines[split_line_index:chunk_end + 1]
        
        return [first_chunk, second_chunk]
    
    return [chunk]
```

### 8.6 è¾¹ç•Œä¼˜å…ˆçº§é‡æ–°è¯„ä¼°

```python
def reassess_boundary_priorities(original_lines):
    """
    é‡æ–°è¯„ä¼°æ‰€æœ‰æ½œåœ¨è¾¹ç•Œçš„ä¼˜å…ˆçº§
    
    è¿”å›:
    - dict: è¡Œå·åˆ°ä¼˜å…ˆçº§çš„æ˜ å°„
    """
    priorities = {}
    
    for i, line in enumerate(original_lines):
        line_stripped = line.strip()
        
        # ä¸­æ–‡ä¸€çº§åºå·ï¼šæœ€é«˜ä¼˜å…ˆçº§
        if is_chinese_major_section(line_stripped):
            priorities[i] = 10
        
        # Markdown H1æ ‡é¢˜ï¼šé«˜ä¼˜å…ˆçº§ï¼ˆä½†éœ€æ£€æŸ¥ä¸Šä¸‹æ–‡ï¼‰
        elif get_heading_level(line_stripped) == 1:
            # æ£€æŸ¥é™„è¿‘æ˜¯å¦æœ‰ä¸­æ–‡åºå·
            nearby_chinese = find_nearby_chinese_section(i, original_lines, 5)
            if nearby_chinese:
                priorities[i] = 5  # é™ä½ä¼˜å…ˆçº§
            else:
                priorities[i] = 9
        
        # Markdown H2æ ‡é¢˜ï¼šä¸­ç­‰ä¼˜å…ˆçº§
        elif get_heading_level(line_stripped) == 2:
            priorities[i] = 7
        
        # å…¶ä»–æ ‡é¢˜ï¼šè¾ƒä½ä¼˜å…ˆçº§
        elif get_heading_level(line_stripped) >= 3:
            priorities[i] = 3
    
    return priorities
```

### 8.7 è¾¹ç•ŒéªŒè¯å’Œè´¨é‡æ£€æŸ¥

```python
def validate_chunk_boundaries_quality(chunks, original_lines):
    """
    éªŒè¯chunkè¾¹ç•Œè´¨é‡
    
    è¿”å›:
    - dict: è´¨é‡è¯„ä¼°ç»“æœ
    """
    quality_report = {
        'total_chunks': len(chunks),
        'boundary_errors': [],
        'quality_score': 0,
        'recommendations': []
    }
    
    # æ£€æµ‹è¾¹ç•Œä½ç½®é”™è¯¯
    boundary_errors = detect_boundary_position_errors(chunks, original_lines)
    quality_report['boundary_errors'] = boundary_errors
    
    # è®¡ç®—è´¨é‡åˆ†æ•°
    error_penalty = len(boundary_errors) * 10
    base_score = 100
    quality_score = max(0, base_score - error_penalty)
    quality_report['quality_score'] = quality_score
    
    # ç”Ÿæˆæ”¹è¿›å»ºè®®
    if boundary_errors:
        quality_report['recommendations'].append(
            f"å‘ç°{len(boundary_errors)}ä¸ªè¾¹ç•Œä½ç½®é”™è¯¯ï¼Œå»ºè®®è¿è¡Œè‡ªåŠ¨ä¿®å¤"
        )
    
    if quality_score < 80:
        quality_report['recommendations'].append(
            "è¾¹ç•Œè´¨é‡è¾ƒä½ï¼Œå»ºè®®é‡æ–°è¯„ä¼°åˆ†å—ç­–ç•¥"
        )
    
    return quality_report
```

## 9. æ¯æ¬¡è½¬æ¢åçš„æ£€æµ‹å’Œè¾“å‡ºæœºåˆ¶

### 9.1 è‡ªåŠ¨æ£€æµ‹æµç¨‹

æ¯æ¬¡æ–‡æ¡£è½¬æ¢å®Œæˆåï¼Œç³»ç»Ÿå°†è‡ªåŠ¨æ‰§è¡Œä»¥ä¸‹æ£€æµ‹æµç¨‹ï¼š

```python
def post_conversion_detection_and_output(optimized_file_path, original_file_path):
    """
    è½¬æ¢åçš„è‡ªåŠ¨æ£€æµ‹å’Œè¾“å‡ºæœºåˆ¶
    
    Args:
        optimized_file_path: ä¼˜åŒ–åçš„æ–‡ä»¶è·¯å¾„
        original_file_path: åŸå§‹æ–‡ä»¶è·¯å¾„
    """
    print(f"\n{'='*60}")
    print(f"æ–‡æ¡£è½¬æ¢å®Œæˆ - å¼€å§‹è´¨é‡æ£€æµ‹")
    print(f"{'='*60}")
    
    # 1. åŸºç¡€ç»Ÿè®¡ä¿¡æ¯
    with open(optimized_file_path, 'r', encoding='utf-8') as f:
        lines = f.readlines()
    
    boundary_count = sum(1 for line in lines if line.strip() == '---CHUNK_BOUNDARY---')
    total_lines = len(lines)
    
    print(f"ğŸ“Š åŸºç¡€ç»Ÿè®¡:")
    print(f"   - æ–‡æ¡£æ€»è¡Œæ•°: {total_lines}")
    print(f"   - è¾¹ç•Œæ ‡è®°æ•°: {boundary_count}")
    print(f"   - é¢„è®¡chunkæ•°: {boundary_count + 1}")
    
    # 2. ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜å…³ç³»æ£€æµ‹
    print(f"\nğŸ” ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜å…³ç³»æ£€æµ‹:")
    title_subtitle_issues = verify_title_subtitle_relationships(lines)
    
    if title_subtitle_issues:
        print(f"   âŒ å‘ç° {len(title_subtitle_issues)} ä¸ªé—®é¢˜:")
        for issue in title_subtitle_issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ªé—®é¢˜
            print(f"      - è¡Œ {issue['line_num']}: {issue['title'][:50]}...")
        if len(title_subtitle_issues) > 5:
            print(f"      - ... è¿˜æœ‰ {len(title_subtitle_issues) - 5} ä¸ªé—®é¢˜")
    else:
        print(f"   âœ… æœªå‘ç°ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜åˆ†ç¦»é—®é¢˜")
    
    # 3. è¾¹ç•Œä½ç½®è´¨é‡æ£€æµ‹
    print(f"\nğŸ¯ è¾¹ç•Œä½ç½®è´¨é‡æ£€æµ‹:")
    chunks = []
    current_chunk = []
    
    for line in lines:
        if line.strip() == '---CHUNK_BOUNDARY---':
            if current_chunk:
                chunks.append(current_chunk)
                current_chunk = []
        else:
            current_chunk.append(line)
    
    if current_chunk:
        chunks.append(current_chunk)
    
    boundary_errors = detect_boundary_position_errors(chunks, lines)
    
    if boundary_errors:
        print(f"   âŒ å‘ç° {len(boundary_errors)} ä¸ªè¾¹ç•Œä½ç½®é”™è¯¯:")
        for error in boundary_errors[:3]:  # æ˜¾ç¤ºå‰3ä¸ªé”™è¯¯
            print(f"      - {error}")
        if len(boundary_errors) > 3:
            print(f"      - ... è¿˜æœ‰ {len(boundary_errors) - 3} ä¸ªé”™è¯¯")
    else:
        print(f"   âœ… æ‰€æœ‰è¾¹ç•Œä½ç½®æ­£ç¡®")
    
    # 4. æ•´ä½“è´¨é‡è¯„åˆ†
    total_issues = len(title_subtitle_issues) + len(boundary_errors)
    max_possible_issues = boundary_count + 50  # å‡è®¾æœ€å¤§å¯èƒ½é—®é¢˜æ•°
    quality_score = max(0, 100 - (total_issues / max_possible_issues * 100))
    
    print(f"\nğŸ“ˆ æ•´ä½“è´¨é‡è¯„åˆ†:")
    print(f"   - è´¨é‡åˆ†æ•°: {quality_score:.1f}/100")
    
    if quality_score >= 95:
        print(f"   - è´¨é‡ç­‰çº§: ğŸŒŸ ä¼˜ç§€")
    elif quality_score >= 85:
        print(f"   - è´¨é‡ç­‰çº§: âœ… è‰¯å¥½")
    elif quality_score >= 70:
        print(f"   - è´¨é‡ç­‰çº§: âš ï¸  ä¸€èˆ¬")
    else:
        print(f"   - è´¨é‡ç­‰çº§: âŒ éœ€è¦æ”¹è¿›")
    
    # 5. æ”¹è¿›å»ºè®®
    print(f"\nğŸ’¡ æ”¹è¿›å»ºè®®:")
    if total_issues == 0:
        print(f"   âœ… æ–‡æ¡£è´¨é‡ä¼˜ç§€ï¼Œæ— éœ€æ”¹è¿›")
    else:
        if title_subtitle_issues:
            print(f"   - å»ºè®®è¿è¡Œä¸»æ ‡é¢˜å­æ ‡é¢˜å…³ç³»ä¿®å¤")
        if boundary_errors:
            print(f"   - å»ºè®®è¿è¡Œè¾¹ç•Œä½ç½®è‡ªåŠ¨ä¿®å¤")
        print(f"   - å¯è€ƒè™‘è°ƒæ•´åˆ†å—å‚æ•°ä»¥æå‡è´¨é‡")
    
    # 6. è¾“å‡ºè¯¦ç»†æŠ¥å‘Šæ–‡ä»¶
    report_file = optimized_file_path.replace('.md', '_quality_report.txt')
    generate_detailed_quality_report(
        report_file, 
        optimized_file_path, 
        total_lines, 
        boundary_count, 
        title_subtitle_issues, 
        boundary_errors, 
        quality_score
    )
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: {report_file}")
    print(f"{'='*60}\n")
    
    return {
        'quality_score': quality_score,
        'total_issues': total_issues,
        'title_subtitle_issues': len(title_subtitle_issues),
        'boundary_errors': len(boundary_errors)
    }

def generate_detailed_quality_report(report_file, optimized_file, total_lines, 
                                   boundary_count, title_subtitle_issues, 
                                   boundary_errors, quality_score):
    """
    ç”Ÿæˆè¯¦ç»†çš„è´¨é‡æ£€æµ‹æŠ¥å‘Š
    """
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(f"æ–‡æ¡£è´¨é‡æ£€æµ‹æŠ¥å‘Š\n")
        f.write(f"{'='*50}\n\n")
        
        f.write(f"æ–‡ä»¶ä¿¡æ¯:\n")
        f.write(f"  - æ–‡ä»¶è·¯å¾„: {optimized_file}\n")
        f.write(f"  - æ£€æµ‹æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        f.write(f"  - æ–‡æ¡£æ€»è¡Œæ•°: {total_lines}\n")
        f.write(f"  - è¾¹ç•Œæ ‡è®°æ•°: {boundary_count}\n\n")
        
        f.write(f"è´¨é‡è¯„åˆ†: {quality_score:.1f}/100\n\n")
        
        f.write(f"ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜å…³ç³»æ£€æµ‹:\n")
        if title_subtitle_issues:
            f.write(f"  å‘ç° {len(title_subtitle_issues)} ä¸ªé—®é¢˜:\n")
            for i, issue in enumerate(title_subtitle_issues, 1):
                f.write(f"    {i}. è¡Œ {issue['line_num']}: {issue['title']}\n")
        else:
            f.write(f"  âœ… æœªå‘ç°é—®é¢˜\n")
        f.write(f"\n")
        
        f.write(f"è¾¹ç•Œä½ç½®è´¨é‡æ£€æµ‹:\n")
        if boundary_errors:
            f.write(f"  å‘ç° {len(boundary_errors)} ä¸ªé”™è¯¯:\n")
            for i, error in enumerate(boundary_errors, 1):
                f.write(f"    {i}. {error}\n")
        else:
            f.write(f"  âœ… æœªå‘ç°é”™è¯¯\n")
        f.write(f"\n")
        
        f.write(f"æ”¹è¿›å»ºè®®:\n")
        if title_subtitle_issues or boundary_errors:
            if title_subtitle_issues:
                f.write(f"  - è¿è¡Œä¸»æ ‡é¢˜å­æ ‡é¢˜å…³ç³»ä¿®å¤\n")
            if boundary_errors:
                f.write(f"  - è¿è¡Œè¾¹ç•Œä½ç½®è‡ªåŠ¨ä¿®å¤\n")
            f.write(f"  - è€ƒè™‘è°ƒæ•´åˆ†å—å‚æ•°\n")
        else:
            f.write(f"  - æ–‡æ¡£è´¨é‡ä¼˜ç§€ï¼Œæ— éœ€æ”¹è¿›\n")
```

### 9.2 é›†æˆåˆ°ä¸»å¤„ç†æµç¨‹

åœ¨ `preprocess.py` çš„ä¸»å‡½æ•°ä¸­é›†æˆæ£€æµ‹æœºåˆ¶ï¼š

```python
def main():
    # ... ç°æœ‰å¤„ç†é€»è¾‘ ...
    
    # å¤„ç†å®Œæˆåè‡ªåŠ¨æ‰§è¡Œæ£€æµ‹
    if optimized_file_path:
        detection_result = post_conversion_detection_and_output(
            optimized_file_path, 
            input_file
        )
        
        # æ ¹æ®æ£€æµ‹ç»“æœå†³å®šæ˜¯å¦éœ€è¦è¿›ä¸€æ­¥å¤„ç†
        if detection_result['total_issues'] > 0:
            print(f"æ£€æµ‹åˆ° {detection_result['total_issues']} ä¸ªé—®é¢˜ï¼Œå»ºè®®æŸ¥çœ‹è¯¦ç»†æŠ¥å‘Š")
        else:
            print(f"æ–‡æ¡£è´¨é‡æ£€æµ‹é€šè¿‡ï¼Œå¯ä»¥è¿›è¡Œåç»­å¤„ç†")
```

### 9.3 è¾“å‡ºæ ¼å¼ç¤ºä¾‹

```
============================================================
æ–‡æ¡£è½¬æ¢å®Œæˆ - å¼€å§‹è´¨é‡æ£€æµ‹
============================================================
ğŸ“Š åŸºç¡€ç»Ÿè®¡:
   - æ–‡æ¡£æ€»è¡Œæ•°: 3456
   - è¾¹ç•Œæ ‡è®°æ•°: 252
   - é¢„è®¡chunkæ•°: 253

ğŸ” ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜å…³ç³»æ£€æµ‹:
   âœ… æœªå‘ç°ä¸»æ ‡é¢˜å’Œå­æ ‡é¢˜åˆ†ç¦»é—®é¢˜

ğŸ¯ è¾¹ç•Œä½ç½®è´¨é‡æ£€æµ‹:
   âœ… æ‰€æœ‰è¾¹ç•Œä½ç½®æ­£ç¡®

ğŸ“ˆ æ•´ä½“è´¨é‡è¯„åˆ†:
   - è´¨é‡åˆ†æ•°: 98.5/100
   - è´¨é‡ç­‰çº§: ğŸŒŸ ä¼˜ç§€

ğŸ’¡ æ”¹è¿›å»ºè®®:
   âœ… æ–‡æ¡£è´¨é‡ä¼˜ç§€ï¼Œæ— éœ€æ”¹è¿›

ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜è‡³: To_be_processed/ä¹³è…ºç™Œè¯Šç–—æŒ‡å—2025_optimized_quality_report.txt
============================================================
```

## é£é™©è¯„ä¼°

- **ä½é£é™©**ï¼šæ™ºèƒ½åˆå¹¶ç­–ç•¥ï¼ˆå‘åå…¼å®¹ï¼‰
- **ä¸­é£é™©**ï¼šåŠ¨æ€åˆ†å—é˜ˆå€¼ï¼ˆå¯èƒ½æ”¹å˜ç°æœ‰è¡Œä¸ºï¼‰
- **ä½é£é™©**ï¼šå¢å¼ºåˆ†å‰²ç‚¹æ£€æµ‹ï¼ˆæ”¹è¿›ç°æœ‰é€»è¾‘ï¼‰
- **ä½é£é™©**ï¼šåå¤„ç†ä¼˜åŒ–ï¼ˆé¢å¤–å¤„ç†æ­¥éª¤ï¼‰
- **ä½é£é™©**ï¼šè¾¹ç•Œæ£€æµ‹å’Œä¿®å¤ï¼ˆæå‡è´¨é‡ï¼Œå¯é€‰å¯ç”¨ï¼‰
- **ä½é£é™©**ï¼šè‡ªåŠ¨æ£€æµ‹è¾“å‡ºæœºåˆ¶ï¼ˆçº¯æ£€æµ‹åŠŸèƒ½ï¼Œä¸å½±å“åŸæœ‰é€»è¾‘ï¼‰